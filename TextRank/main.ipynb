{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T10:03:34.125063Z",
     "iopub.status.busy": "2024-10-19T10:03:34.124540Z",
     "iopub.status.idle": "2024-10-19T10:03:34.141657Z",
     "shell.execute_reply": "2024-10-19T10:03:34.140961Z",
     "shell.execute_reply.started": "2024-10-19T10:03:34.125037Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import jieba.posseg as posseg\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "###################################################\n",
    "# TextRank实现\n",
    "###################################################\n",
    "# 停用词路径\n",
    "stopwords_path = 'stopwords.txt'\n",
    "# 需要排除的词性\n",
    "stopPOS = []\n",
    "\n",
    "# 读取停用词\n",
    "with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "    stopwords = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def segment_text_to_sentence(text):\n",
    "    # 将文本分割成句子\n",
    "    sentences = re.split(r'[。！？!?]', text)\n",
    "    sentences = [sentence.strip().replace(\" \", \"\").replace('\\n','') for sentence in sentences if sentence.strip()]\n",
    "    return sentences\n",
    "\n",
    "def segment_text_to_words(text, use_stopwords):\n",
    "    # 分词并去除停用词\n",
    "    global stopPOS, stopwords\n",
    "    stopPOS = [item.lower() for item in stopPOS]\n",
    "    words = posseg.cut(text)\n",
    "    if use_stopwords:\n",
    "        words = [word for word, flag in words if flag[0].lower() not in stopPOS and word not in stopwords]\n",
    "    else:\n",
    "        words = [word for word, flag in words if flag[0].lower() not in stopPOS]\n",
    "    words = set(words)\n",
    "\n",
    "    return words\n",
    "\n",
    "def original_similarity_matrix(sentences, use_stopwords):\n",
    "    # 计算原始相似性矩阵\n",
    "    sentence_words = [set(segment_text_to_words(item, use_stopwords)) for item in sentences]\n",
    "    # print(sentence_words)\n",
    "    size = len(sentences)\n",
    "    similarity_matrix = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        for j in range(i+1, size):\n",
    "            if len(sentence_words[i]) == 0 or len(sentence_words[j]) == 0:\n",
    "                similarity = 0\n",
    "            else:\n",
    "                # 计算相似性\n",
    "                similarity = len(sentence_words[i] & sentence_words[j]) / (np.log(len(sentence_words[i])) + np.log(len(sentence_words[i])) + 1e-10)\n",
    "            similarity_matrix[i][j] = similarity_matrix[j][i] = similarity\n",
    "    return similarity_matrix\n",
    "\n",
    "def cosine_tfidf_similarity_matrix(sentences, use_stopwords):\n",
    "    # 计算基于TF-IDF的余弦相似性矩阵\n",
    "    sentence_words = [' '.join(segment_text_to_words(item, use_stopwords)) for item in sentences]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentence_words)\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # 将对角线元素设置为0，避免自身与自身的相似性干扰\n",
    "    np.fill_diagonal(similarity_matrix, 0)\n",
    "    return similarity_matrix\n",
    "\n",
    "def summarize_text_rank(text, d=0.85, iter_num=200, top=3, method='默认方式', use_stopwords=True):\n",
    "    sentences = segment_text_to_sentence(text)\n",
    "\n",
    "    print('---------开始----------------------------------------')\n",
    "    if method == '默认方式':\n",
    "        edge_weight = original_similarity_matrix(sentences, use_stopwords)\n",
    "    elif method == 'TF-IDF':\n",
    "        edge_weight = cosine_tfidf_similarity_matrix(sentences, use_stopwords)\n",
    "\n",
    "    node_weight = np.ones((len(sentences)))\n",
    "    # print(node_weight)\n",
    "    \n",
    "#     print(\"句子间相似性计算(边的权重)\")\n",
    "#     print(edge_weight)\n",
    "\n",
    "#     print(\"\\n句子节点参数迭代更新：\")\n",
    "    for num in range(iter_num):                \n",
    "        # TextRank迭代公式\n",
    "        # print(node_weight)\n",
    "        node_weight_new = (1-d) + d * node_weight @ (edge_weight / (edge_weight.sum(axis=-1) + 1e-10)).T\n",
    "        if ((node_weight_new - node_weight)**2).sum() < 1e-10:\n",
    "            break\n",
    "        node_weight = node_weight_new\n",
    "        # print(node_weight)\n",
    "\n",
    "    if num < iter_num:\n",
    "        print('迭代{}次，收敛'.format(num))\n",
    "    else:\n",
    "        print('迭代{}次，未收敛'.format(num))\n",
    "\n",
    "    sorted_indices = np.argsort(node_weight)[::-1]\n",
    "\n",
    "    # 获取最大的几个值及其对应的索引\n",
    "    top_indices = sorted(sorted_indices[:top])\n",
    "    top_values = node_weight[top_indices]\n",
    "\n",
    "    print('最大的{}个值：'.format(top), top_values)\n",
    "    print('对应的索引：', top_indices)\n",
    "    print('结果：')\n",
    "    result = ''\n",
    "    for idx in top_indices:\n",
    "        result += sentences[idx] + '。\\n'\n",
    "    print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "# # # 示例\n",
    "# text = '记者7日从江苏省苏州市有关部门证实,该市一名初中副校长涉嫌泄露联考考题被停职,纪委已介入调查。今年4月,苏州市吴江区举行初三联考,震泽初级中学是联考学校之一,联考成绩将直接影响考生能否进入四星级高中(即重点高中)。就在考试前一天,考卷题目已在网上疯传,引发社会关注。据知情人士介绍,疑似震泽初级中学副校长将题目提前泄露给自己亲戚,然后这位亲戚又将题目进行了散播,导致题目最终被传到了网上。据苏州市吴江区教育局副局长沈正元介绍,泄题事件发生后,教育局于5月紧急推出了学校自主招生考试政策,以弥补泄题造成的不良后果。5月11日,教育局对涉嫌泄题违纪的震泽初级中学副校长作出停职处理,区纪委也已介入调查,教育部门会根据纪委处理意见进行相应处理。另据家长反映,泄题事件中一些“得题考生”出现在了震泽中学的保送名单里。对此,沈正元回应称,目前对涉嫌的涉事成年人进行了初步处理,纪委尚未作出明确处理意见,所以推优、自主招生等还按正常程序进行,因此出现了市民反映的疑似“得题考生”出现在名单中的情况。具体处理意见将在调查结果公布后作出,教育局将尽快进行相关调查工作,保障学生正当利益。(记者刘巍巍'\n",
    "# summarize_text_rank(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T10:03:52.561610Z",
     "iopub.status.busy": "2024-10-19T10:03:52.561142Z",
     "iopub.status.idle": "2024-10-19T10:03:53.516724Z",
     "shell.execute_reply": "2024-10-19T10:03:53.515784Z",
     "shell.execute_reply.started": "2024-10-19T10:03:52.561583Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLMForConditionalGeneration(\n",
       "  (glm): GLMModel(\n",
       "    (word_embeddings): VocabEmbedding()\n",
       "    (transformer): GLMStack(\n",
       "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(1025, 1024)\n",
       "      (block_position_embeddings): Embedding(1025, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x GLMBlock(\n",
       "          (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attention): SelfAttention(\n",
       "            (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载模型\n",
    "# 检查是否有可用的 GPU\n",
    "path='../checkpoint-153'  #模型存在的文件夹\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(path,trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(path,trust_remote_code=True)\n",
    "# 将模型移动到 GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T10:03:57.013194Z",
     "iopub.status.busy": "2024-10-19T10:03:57.012697Z",
     "iopub.status.idle": "2024-10-19T10:04:04.490983Z",
     "shell.execute_reply": "2024-10-19T10:04:04.490076Z",
     "shell.execute_reply.started": "2024-10-19T10:03:57.013168Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLMForConditionalGeneration(\n",
       "  (glm): GLMModel(\n",
       "    (word_embeddings): VocabEmbedding()\n",
       "    (transformer): GLMStack(\n",
       "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(1025, 1024)\n",
       "      (block_position_embeddings): Embedding(1025, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x GLMBlock(\n",
       "          (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attention): SelfAttention(\n",
       "            (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mt5='../checkpoint-140'\n",
    "# 检查是否有可用的 GPU\n",
    "device_mt5 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_mt5 = AutoModelForSeq2SeqLM.from_pretrained(path_mt5,trust_remote_code=True)\n",
    "tokenizer_mt5 = AutoTokenizer.from_pretrained(path_mt5,trust_remote_code=True)\n",
    "# 将模型移动到 GPU\n",
    "model_mt5.to(device_mt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T10:04:06.910951Z",
     "iopub.status.busy": "2024-10-19T10:04:06.910352Z",
     "iopub.status.idle": "2024-10-19T10:04:06.920218Z",
     "shell.execute_reply": "2024-10-19T10:04:06.919325Z",
     "shell.execute_reply.started": "2024-10-19T10:04:06.910922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summary_glm(input_text, tokenizer=tokenizer, model=model, device=device):\n",
    "    # 生成摘要的输入\n",
    "    inputs = tokenizer(\"摘要生成: \\n\" + input_text + tokenizer.mask_token, return_tensors=\"pt\")\n",
    "    inputs = tokenizer.build_inputs_for_generation(inputs, max_gen_length=64)\n",
    "\n",
    "    # 将输入张量移动到与模型相同的设备\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # 生成输出\n",
    "    output = model.generate(**inputs, max_new_tokens=64, eos_token_id=tokenizer.eop_token_id, do_sample=True)\n",
    "\n",
    "    # 解码生成的文本\n",
    "    text = tokenizer.decode(output[0].tolist())\n",
    "    # print(text)\n",
    "\n",
    "    # 提取数据\n",
    "    start_marker = '<|startofpiece|>'\n",
    "    end_marker = '<|endofpiece|>'\n",
    "    # 找到起始和结束位置\n",
    "    start_index = text.find(start_marker) + len(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "    # 提取所需数据\n",
    "    extracted_data = text[start_index:end_index].strip()\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "def summary_mt5(input_text, tokenizer=tokenizer_mt5, model=model_mt5, device=device):\n",
    "    # 生成摘要的输入\n",
    "    inputs = tokenizer(\"摘要生成: \\n\" + input_text + tokenizer.mask_token, return_tensors=\"pt\")\n",
    "    inputs = tokenizer.build_inputs_for_generation(inputs, max_gen_length=64)\n",
    "\n",
    "    # 将输入张量移动到与模型相同的设备\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # 生成输出\n",
    "    output = model.generate(**inputs, max_new_tokens=64, eos_token_id=tokenizer.eop_token_id, do_sample=True)\n",
    "\n",
    "    # 解码生成的文本\n",
    "    text = tokenizer.decode(output[0].tolist())\n",
    "    # print(text)\n",
    "\n",
    "    # 提取数据\n",
    "    start_marker = '<|startofpiece|>'\n",
    "    end_marker = '<|endofpiece|>'\n",
    "    # 找到起始和结束位置\n",
    "    start_index = text.find(start_marker) + len(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "    # 提取所需数据\n",
    "    extracted_data = text[start_index:end_index].strip()\n",
    "\n",
    "    return extracted_data\n",
    "# input_text = \" 近阶段苹果的诸多投资者无疑仿佛徜徉在九霄云外。根据苹果官方公布的总利润再次刷新历史，公司的股票也再创新高。此图表非常清晰的展示了苹果股票的“孤独”，其中Y轴代表这些公司目前的市值，X轴代表年增长率涨幅情况。\"\n",
    "# print('原文内容： '+input_text)\n",
    "# summary = summary_mt5(input_text, tokenizer_mt5, model_mt5, device_mt5)\n",
    "# print('\\n文本摘要内容为: ' + summary)\n",
    "# summary = generate_summary(input_text, tokenizer, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T10:04:08.841629Z",
     "iopub.status.busy": "2024-10-19T10:04:08.841071Z",
     "iopub.status.idle": "2024-10-19T10:04:08.890142Z",
     "shell.execute_reply": "2024-10-19T10:04:08.889453Z",
     "shell.execute_reply.started": "2024-10-19T10:04:08.841602Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7903c979418d41a9be6b4299b71812f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='150px', width='70%'), placeholder='输入文本')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4fcc4cc12a479681588d419936d5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='使用停用词', layout=Layout(width='15%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27adaf1be8d4161b33168f244e0ee73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.85, description='阻尼系数:', layout=Layout(width='25%')), IntText(value=3, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c9253144a949a383c03e38f8c7375c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='TextRank生成摘要', layout=Layout(width='33%'), style=ButtonStyle()), Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a915df5073401797b54f0aab0088c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='150px', width='70%'), placeholder='TextRank输出文本')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f266b20430471282f3b266dc562c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='150px', width='70%'), placeholder='GLM输出文本/nlpcc数据集模型')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961e2c8c32bc451ab94b95f50ce9d79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='150px', width='70%'), placeholder='MT5输出文本/LCSTS数据集模型')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import Javascript\n",
    "\n",
    "import jieba\n",
    "###################################################\n",
    "# UI界面实现\n",
    "###################################################\n",
    "\n",
    "def summarize_text(change):\n",
    "    input_text = input_text_widget.value\n",
    "    d = float(d_entry.value) if d_entry.value else 0.85\n",
    "    top = int(top_entry.value) if top_entry.value else 3\n",
    "    processing_method = processing_method_dropdown.value\n",
    "    use_stopwords = use_stopwords_checkbox.value\n",
    "    summary = summarize_text_rank(input_text, d=d, top=top, method=processing_method, use_stopwords=use_stopwords)\n",
    "    output_text_widget.value = summary\n",
    "\n",
    "def summarize_text_glm(change):\n",
    "    input_text = input_text_widget.value\n",
    "    summary_result = summary_glm(input_text, tokenizer, model, device)\n",
    "    output_text_widget_glm.value = summary_result\n",
    "    \n",
    "def summarize_text_mt5(change):\n",
    "    input_text = input_text_widget.value\n",
    "    summary_result = summary_mt5(input_text, tokenizer_mt5, model_mt5, device_mt5)\n",
    "    output_text_widget_mt5.value = summary_result\n",
    "\n",
    "# 创建输入文本框\n",
    "input_text_widget = widgets.Textarea(\n",
    "    layout=Layout(width='70%', height='150px'),\n",
    "    placeholder='输入文本'\n",
    ")\n",
    "display(input_text_widget)\n",
    "\n",
    "# 创建TextRank参数设置\n",
    "use_stopwords_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    layout=Layout(width='15%'),\n",
    "    description='使用停用词'\n",
    ")\n",
    "d_entry = widgets.FloatText(\n",
    "    value=0.85,\n",
    "    layout=Layout(width='25%'),\n",
    "    description='阻尼系数:'\n",
    ")\n",
    "top_entry = widgets.IntText(\n",
    "    value=3,\n",
    "    layout=Layout(width='25%'),\n",
    "    description='摘要句数:'\n",
    ")\n",
    "processing_method_dropdown = widgets.Dropdown(\n",
    "    options=['默认方式', 'TF-IDF'],\n",
    "    value='默认方式',\n",
    "    layout=Layout(width='35%'),\n",
    "    description='相似度度量:'\n",
    ")\n",
    "display(use_stopwords_checkbox)\n",
    "# display(use_stopwords_checkbox, d_entry, top_entry, processing_method_dropdown)\n",
    "display(widgets.HBox([d_entry,top_entry, processing_method_dropdown]))\n",
    "\n",
    "# 创建按钮，用于触发文本摘要\n",
    "summarize_button = widgets.Button(\n",
    "    description='TextRank生成摘要',\n",
    "    layout=Layout(width='33%')\n",
    ")\n",
    "summarize_button.on_click(summarize_text)\n",
    "\n",
    "summarize_button_glm = widgets.Button(\n",
    "    description='GLM生成摘要',\n",
    "    layout=Layout(width='33%')\n",
    ")\n",
    "summarize_button_glm.on_click(summarize_text_glm)\n",
    "\n",
    "summarize_button_mt5 = widgets.Button(\n",
    "    description='MT5生成摘要',\n",
    "    layout=Layout(width='33%')\n",
    ")\n",
    "summarize_button_mt5.on_click(summarize_text_mt5)\n",
    "\n",
    "display(widgets.HBox([summarize_button, summarize_button_glm, summarize_button_mt5]))\n",
    "\n",
    "# 创建输出文本框\n",
    "output_text_widget = widgets.Textarea(\n",
    "    layout=Layout(width='70%', height='150px'),\n",
    "    placeholder='TextRank输出文本'\n",
    ")\n",
    "output_text_widget_glm = widgets.Textarea(\n",
    "    layout=Layout(width='70%', height='150px'),\n",
    "    placeholder='GLM输出文本/nlpcc数据集模型'\n",
    ")\n",
    "output_text_widget_mt5 = widgets.Textarea(\n",
    "    layout=Layout(width='70%', height='150px'),\n",
    "    placeholder='MT5输出文本/LCSTS数据集模型'\n",
    ")\n",
    "display(output_text_widget)\n",
    "display(output_text_widget_glm)\n",
    "display(output_text_widget_mt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
