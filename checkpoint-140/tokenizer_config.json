{
  "add_prefix_space": false,
  "added_tokens_decoder": {
    "50000": {
      "content": "<|endoftext|>",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    },
    "50001": {
      "content": "[SEP]",
      "lstrip": false,
      "normalized": true,
      "rstrip": false,
      "single_word": false,
      "special": false
    },
    "50002": {
      "content": "[CLS]",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    },
    "50003": {
      "content": "[MASK]",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    },
    "50004": {
      "content": "[UNUSED1]",
      "lstrip": false,
      "normalized": true,
      "rstrip": false,
      "single_word": false,
      "special": false
    },
    "50005": {
      "content": "[UNUSED2]",
      "lstrip": false,
      "normalized": true,
      "rstrip": false,
      "single_word": false,
      "special": false
    },
    "50006": {
      "content": "<|startofpiece|>",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    },
    "50007": {
      "content": "<|endofpiece|>",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    },
    "50008": {
      "content": "[sMASK]",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    },
    "50009": {
      "content": "[gMASK]",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    },
    "50010": {
      "content": "[UNK]",
      "lstrip": false,
      "normalized": false,
      "rstrip": false,
      "single_word": false,
      "special": true
    }
  },
  "additional_special_tokens": [
    "<|startofpiece|>",
    "<|endofpiece|>",
    "[gMASK]",
    "[sMASK]"
  ],
  "auto_map": {
    "AutoTokenizer": [
      "tokenization_glm.GLMChineseTokenizer",
      null
    ]
  },
  "clean_up_tokenization_spaces": true,
  "cls_token": "[CLS]",
  "eos_token": "<|endoftext|>",
  "mask_token": "[MASK]",
  "model_max_length": 1000000000000000019884624838656,
  "pad_token": "<|endoftext|>",
  "tokenizer_class": "GLMChineseTokenizer",
  "unk_token": "[UNK]",
  "use_fast": false
}
